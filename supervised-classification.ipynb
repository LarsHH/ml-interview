{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.datasets.samples_generator import make_blobs, make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "p = 3\n",
    "X, y = make_classification(n_samples=N, n_features=p, n_informative=p, n_redundant=0, n_repeated=0, n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression aims to model a binary outcome using a linear function in feature space. In particular, we model the log-odds as a linear combination of the predictor variables: $$\\log{\\frac{\\mathrm{Pr}(y_i = 1|X)}{1-\\mathrm{Pr}(y_i = 1|X)}} = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\ldots + \\beta_p x_{ip} = \\boldsymbol{\\beta}^T\\mathbf{x}_i$$, where $\\mathbf{x}_i = (1, x_{i1}, \\ldots, x_{ip})^T$.\n",
    "One can show that this can be rewritten as: $$\\mathrm{Pr}(y_i = 1|X)=\\frac{\\exp{\\boldsymbol{\\beta}^T\\mathbf{x}_i}}{1+\\exp{\\boldsymbol{\\beta}^T\\mathbf{x}_i}}=\\frac{1}{1+\\exp{(-\\boldsymbol{\\beta}^T\\mathbf{x}_i)}}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that $y \\sim Bin(\\mathrm{Pr}(y_i = 1|X))$ we can use the binomial likelihood or binomial cross-entropy loss to fit the model: $$L(\\boldsymbol{\\beta};\\mathbf{X}, \\mathbf{y}) = \\prod_i^n p^{y_i} (1-p)^{1-y_i}$$ where $\\mathbf{X} = (\\mathbf{x}_1, \\ldots, \\mathbf{x}_n)^T$ is a design matrix with the feature vectors as rows, $\\mathbf{y}=(y_1,\\ldots,y_n)^T$, and $p=\\mathrm{Pr}(y_i = 1|X)$. We can obtain the log-likelihood as $$\\ell(\\boldsymbol{\\beta};\\mathbf{X}, \\mathbf{y})=\\sum_i^n y_i \\log{(p)} + (1-y_i)\\log{(1-p)}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take the derivative with respect to $\\boldsymbol{\\beta}$ and set to zero. Note that $\\frac{\\partial p}{\\partial \\boldsymbol{\\beta}} = p (1-p) \\mathbf{x}_i$. We obtain $$\\frac{\\partial \\ell}{\\partial \\boldsymbol{\\beta}} = \\sum_i^n \\mathbf{x}_i^T (y_i - p_i)$$ (it takes a couple of lines to work through). We further get the second derivative as $$\\frac{\\partial \\ell}{\\partial \\boldsymbol{\\beta}\\boldsymbol{\\beta}^T} = \\sum_i^n  p_i(1-p_i)\\mathbf{x}_i\\mathbf{x}_i^T$$. Now we can use Newton-Raphson to iteratively update the parameters: $$\\boldsymbol{\\beta}^{t+1} = \\boldsymbol{\\beta}^{t} - \\left( \\frac{\\partial \\ell}{\\partial \\boldsymbol{\\beta}\\boldsymbol{\\beta}^T} \\right)^{-1} \\frac{\\partial \\ell}{\\partial \\boldsymbol{\\beta}}$$ where the derivatives are evaluated at $\\boldsymbol{\\beta}^{t}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further write this as follows: $$\\frac{\\partial \\ell}{\\partial \\boldsymbol{\\beta}} = \\mathbf{X}^T(\\mathbf{y}-\\mathbf{p})$$,\n",
    "$$\\frac{\\partial \\ell}{\\partial \\boldsymbol{\\beta}\\boldsymbol{\\beta}^T}= -\\mathbf{X}^T \\mathbf{W} \\mathbf{X}$$ where $\\mathbf{W} = \\mathrm{diag}(\\mathbf{p}(1-\\mathbf{p}))$ that is a diagonal matrix with $p_i(1-p_i)$ along its diagonal. Then an update can be written as $$\\boldsymbol{\\beta}^{t+1} = \\boldsymbol{\\beta}^{t} + (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{y}-\\mathbf{p})$$ which after rearranging can be written as $$\\boldsymbol{\\beta}^{t+1}=(\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{W}(\\mathbf{X}\\boldsymbol{\\beta}^{t}+\\mathbf{W}^{-1}(\\mathbf{y}-\\mathbf{p}))$$. This is also known as the iteratively reweighted least squares algorithm (IRLS) because it has the form of a least squares update on a transformed response. A good starting value for the $\\beta_j$ values is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.concatenate([np.ones((N,1)), X], axis=1)\n",
    "sigmoid = lambda z: 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "-13.862943611198906\n",
      "[-0.69712367  0.75797279 -1.18168976  0.73446252]\n",
      "-3.085462595608325\n",
      "[-1.09474536  1.20285868 -1.90649182  1.24847506]\n",
      "-1.1478580182013316\n",
      "[-1.46458468  1.63291359 -2.61258951  1.77757897]\n",
      "-0.44281074096931144\n",
      "[-1.84315806  2.08024807 -3.33447255  2.33079118]\n",
      "-0.1716131772388498\n",
      "[-2.2474597   2.55513689 -4.08152384  2.90718279]\n",
      "-0.06627108741433989\n",
      "[-2.68445507  3.06015924 -4.85587836  3.50374865]\n",
      "-0.025434057020906203\n",
      "[-3.15381521  3.59364408 -5.65655077  4.11698952]\n",
      "-0.009696397576888463\n",
      "[-3.65008844  4.15122336 -6.48106017  4.74354061]\n",
      "-0.0036736819117452304\n",
      "[-4.16496947  4.72713553 -7.32637813  5.38043293]\n",
      "-0.0013843279479963423\n",
      "[-4.68909123  5.31520827 -8.18951394  6.0250999 ]\n",
      "-0.0005192735486494641\n",
      "[-5.21307021  5.90941993 -9.06781254  6.67528401]\n",
      "-0.00019404923480903117\n",
      "[-5.72798643  6.50414714 -9.95904775  7.32895687]\n",
      "-7.228925125446261e-05\n",
      "[ -6.22564102   7.09428498 -10.86139888   7.98429023]\n",
      "-2.6860872568431887e-05\n",
      "[ -6.69888969   7.67540088 -11.77337247   8.63967903]\n",
      "-9.95976135978789e-06\n",
      "[ -7.1422113    8.24400966 -12.69370202   9.29380832]\n",
      "-3.6866007625528165e-06\n",
      "[ -7.55245869   8.79794506 -13.62124589   9.94574489]\n",
      "nan\n",
      "[ -7.92947967   9.33666785 -14.5549068   10.59501146]\n",
      "nan\n",
      "[ -8.27615058   9.86127418 -15.49359964  11.24158747]\n",
      "nan\n",
      "[ -8.59758094  10.37407863 -16.43627776  11.88580621]\n",
      "nan\n",
      "[ -8.89977563  10.87791786 -17.38199461  12.52818276]\n",
      "nan\n",
      "[ -9.18838243  11.37549728 -18.32995801  13.16924926]\n",
      "nan\n",
      "[ -9.46797272  11.86901178 -19.27954987  13.8094539 ]\n",
      "nan\n",
      "[ -9.74187171  12.36004966 -20.23031279  14.44912759]\n",
      "nan\n",
      "[-10.01233164  12.84967424 -21.18191869  15.08849474]\n",
      "nan\n",
      "[-10.28078263  13.33854675 -22.13413705  15.72769593]\n",
      "nan\n",
      "[-10.5481497   13.82708469 -23.08680243  16.36682076]\n",
      "nan\n",
      "[-10.81492879  14.31549773 -24.03980259  17.00591545]\n",
      "nan\n",
      "[-11.08112361  14.80375364 -24.9930805   17.6449725 ]\n",
      "nan\n",
      "[-11.34788745  15.29240825 -25.94649093  18.28411334]\n",
      "nan\n",
      "[-11.61390329  15.78077417 -26.90011263  18.92318648]\n",
      "nan\n",
      "[-11.88011398  16.26929011 -27.85380618  19.56229259]\n",
      "nan\n",
      "[-12.14648044  16.75791474 -28.80754138  20.20142407]\n",
      "nan\n",
      "[-12.41292497  17.24684795 -29.76165563  20.84058905]\n",
      "nan\n",
      "[-12.67947007  17.7358334  -30.71577149  21.47976892]\n",
      "nan\n",
      "[-12.94609456  18.2248601  -31.66988865  22.11896055]\n",
      "nan\n",
      "[-13.21278181  18.71391939 -32.62400683  22.75816149]\n",
      "nan\n",
      "[-13.4795186   19.20300446 -33.57812589  23.39736982]\n",
      "nan\n",
      "[-13.74629481  19.69210977 -34.53224534  24.0365838 ]\n",
      "nan\n",
      "[-14.01310182  20.18123132 -35.48636557  24.67580256]\n",
      "nan\n",
      "[-15.01310182  20.18123132 -35.48636557  24.67580256]\n",
      "nan\n",
      "[-15.27993303  20.67036583 -36.44048665  25.31502526]\n",
      "nan\n",
      "[-16.27993303  20.67036583 -36.44048665  25.31502526]\n",
      "nan\n",
      "[-16.5467837   21.15951039 -37.394608    25.95425081]\n",
      "nan\n",
      "[-17.5467837   21.15951039 -37.39460799  25.95425081]\n",
      "nan\n",
      "[-17.8136498   21.64866289 -38.34872951  26.59347858]\n",
      "nan\n",
      "[-18.8136498   21.64866289 -38.34872951  26.59347858]\n",
      "nan\n",
      "[-19.08052811  22.13782166 -39.30285115  27.23270811]\n",
      "nan\n",
      "[-20.08052811  22.13782166 -39.30285115  27.23270811]\n",
      "nan\n",
      "[-20.3474161   22.6269854  -40.2569729   27.87193902]\n",
      "nan\n",
      "[-21.3474161   22.6269854  -40.2569729   27.87193902]\n",
      "nan\n",
      "[-21.61431174  23.11615307 -41.21109473  28.51117104]\n",
      "nan\n",
      "[-22.61431174  23.11615306 -41.21109473  28.51117104]\n",
      "nan\n",
      "[-22.88121346  23.60532386 -42.16521662  29.15040394]\n",
      "nan\n",
      "[-23.88121346  23.60532386 -42.16521662  29.15040394]\n",
      "nan\n",
      "[-24.14812008  24.09449722 -43.11933856  29.78963753]\n",
      "nan\n",
      "[-25.14812008  24.09449722 -43.11933856  29.78963753]\n",
      "nan\n",
      "[-25.41503063  24.58367206 -44.07346051  30.42887171]\n",
      "nan\n",
      "[-26.41503063  24.58367206 -44.07346051  30.42887171]\n",
      "nan\n",
      "[-26.681945    25.07285358 -45.02758234  31.06810721]\n",
      "nan\n",
      "[-27.681945    25.07285358 -45.02758234  31.06810721]\n",
      "nan\n",
      "[-27.94903484  25.56208087 -45.98170298  31.70734748]\n",
      "nan\n",
      "[-28.94903484  25.56208088 -45.98170298  31.70734748]\n",
      "nan\n",
      "[-29.2156364   26.05109455 -46.93580454  32.34659919]\n",
      "nan\n",
      "[-30.2156364   26.05109454 -46.93580454  32.34659918]\n",
      "nan\n",
      "[-30.4812614   26.53839923 -47.8899061   32.98575934]\n",
      "nan\n",
      "[-31.48126139  26.53839922 -47.8899061   32.98575934]\n",
      "nan\n",
      "[-31.76251139  27.02277422 -48.84400766  33.62443121]\n",
      "nan\n",
      "[-32.76251139  27.02277422 -48.84400766  33.62443121]\n",
      "nan\n",
      "[-33.01251139  27.64777422 -49.81275766  34.28068121]\n",
      "nan\n",
      "[-34.01251137  27.64777422 -49.81275767  34.28068121]\n",
      "nan\n",
      "[-35.01251137  28.14777422 -50.75025767  34.90568121]\n",
      "nan\n",
      "[-37.01251137  30.14777422 -51.75025767  35.40568121]\n",
      "nan\n",
      "[-38.01251132  30.14777419 -51.75025766  35.40568121]\n",
      "nan\n",
      "[-39.01251133  30.1477742  -51.75025766  35.40568121]\n",
      "nan\n",
      "[-35.01251133  30.1477742  -52.75025766  36.40568121]\n",
      "nan\n",
      "[-36.01251127  30.14777418 -52.75025768  36.40568122]\n",
      "nan\n",
      "[-37.01251128  30.1477742  -52.75025768  36.40568122]\n",
      "nan\n",
      "[-38.01251123  30.14777418 -52.75025769  36.40568123]\n",
      "nan\n",
      "[-39.01251119  30.14777417 -52.75025771  36.40568123]\n",
      "nan\n",
      "[-40.01251116  30.14777417 -52.75025773  36.40568124]\n",
      "nan\n",
      "[-40.01251116  30.14777417 -53.62525773  36.96818124]\n",
      "nan\n",
      "[-39.01251116  30.14777417 -54.62525773  37.37443124]\n",
      "nan\n",
      "[-40.0125112   30.1477742  -54.62525773  37.37443124]\n",
      "nan\n",
      "[-41.01251121  30.14777422 -54.62525774  37.37443124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larshertel/python3env/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/larshertel/python3env/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in multiply\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6cf36c283950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mold_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbeta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloglik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglik\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "epsilon = 0.1\n",
    "beta = np.zeros((p+1,))\n",
    "for _ in range(max_iter):\n",
    "    prob = sigmoid(np.dot(X_, beta))\n",
    "    print(beta)\n",
    "    W = np.diag(prob*(1-prob))\n",
    "    old_beta = beta.copy()\n",
    "    beta += np.dot(inv(np.dot(np.dot(X_.T, W), X_)), np.dot(X_.T, y-prob))\n",
    "    loglik = np.sum(y*np.log(prob)+(1-y)*np.log(1-prob))\n",
    "    print(loglik)\n",
    "    if np.sum(np.abs(old_beta - beta)) < epsilon:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "To do: add discrete feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Mean(X|Y=0), Mean(X|Y=1)], shape=(p,2)\n",
    "means = np.vstack([X[y==0].mean(0), X[y==1].mean(0)]).T\n",
    "# [Var(X|Y=0), Var(X|Y=1)], shape=(p,2)\n",
    "variances = np.vstack([X[y==0].var(0), X[y==1].var(0)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x,m,v):\n",
    "    return np.exp(-(x-m)**2/(2*v))/np.sqrt(2*np.pi*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [P(Y=0), P(Y=1)], shape=(2,)\n",
    "prevalence = np.array([1-y.mean(), y.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: X.shape = (20,3), means.shape = (3,2)\n",
    "# Add axis 2 to X to broadcast the last axis of means (that is classes)\n",
    "# Add axis 0 to means and variances to broadcast of the zeroeth axis of X (that is data points)\n",
    "def naive_bayes(X_):\n",
    "    return np.argmax(gaussian(X_[:,:,None],means[None,:,:],variances[None,:,:]).prod(1) * prevalence,\n",
    "                     axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
